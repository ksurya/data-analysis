{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model: Two Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_src = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(os.path.join(data_src, \"train.json\"))\n",
    "test_df = pd.read_json(os.path.join(data_src, \"test.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    print \"started..\"\n",
    "    # convert to datetime. derive new things.. for convenience\n",
    "    df.created = pd.to_datetime(df.created)\n",
    "    df[\"created_month\"] = df.created.dt.month\n",
    "    df[\"created_year\"] = df.created.dt.year\n",
    "    df[\"created_quarter\"] = df.created.dt.quarter\n",
    "    \n",
    "    # days count\n",
    "    today = datetime.datetime.now()\n",
    "    df[\"days_count\"] = df.created.apply(lambda d: (today - d).days)\n",
    "    df.days_count\n",
    "    \n",
    "    # photos count\n",
    "    df[\"photos_count\"] = df.photos.apply(lambda x: len(x))\n",
    "    \n",
    "    # clean listing-features\n",
    "    print \"cleaning features..\"\n",
    "    ignore_words = stopwords.words(\"english\")\n",
    "    escape_chars = r\"[-!:*;/.&<>^()#@$_+=,]\"\n",
    "    def clean_features(v):\n",
    "        new_v = []\n",
    "        for each in v:\n",
    "            cleaned_each = re.sub(escape_chars, \" \", each.lower()).split()\n",
    "            cleaned_each = \" \".join([i for i in cleaned_each if i not in ignore_words])\n",
    "            new_v.append(cleaned_each)\n",
    "        return new_v\n",
    "    df[\"features_cleaned\"] = df.features.apply(clean_features)\n",
    "    \n",
    "    # clean description\n",
    "    print \"cleaning description..\"\n",
    "    escape_chars = r\"[-!:*;/.&<>^()#@$_+=,]\"\n",
    "    def clean_description(v):\n",
    "        soup = BeautifulSoup(v, \"html.parser\")\n",
    "        words = re.sub(escape_chars, \" \", soup.get_text().lower()).split()\n",
    "        new_v = \" \".join([i for i in words if i not in ignore_words])\n",
    "        return new_v\n",
    "    df[\"description_cleaned\"] = df.description.apply(clean_description)\n",
    "    \n",
    "    # price. Ignore prices that are too large; find price per room.\n",
    "    df = df.drop(df[df.price > 10**5].index)\n",
    "    df[\"price_per_room\"] = df.price / (df.bedrooms + df.bathrooms + 1)\n",
    "    \n",
    "    # group by lat-lng..\n",
    "    grouped = train_df.groupby([\"lat_lng_group\"]).mean()\n",
    "    def price_group_by(row):\n",
    "        grp = row.lat_lng_group\n",
    "        return grouped.loc[grp].price\n",
    "    df[\"price_per_lat_lng\"] = df.apply(price_group_by, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_tailored_features(df):\n",
    "    keywords = [\n",
    "        (\"dog\", \"allowed\"), (\"cat\", \"allowed\"), (\"fitness\",), (\"laundry\",), (\"dishwasher\",),\n",
    "        (\"hardwood\",), (\"elevator\",), (\"doorman\",), (\"outdoor\", \"space\"), (\"new\", \"construction\"),\n",
    "        (\"internet\",), (\"high\", \"ceiling\"), (\"swimming\", \"pool\"), (\"terrace\",), (\"balcony\",),\n",
    "        (\"pet\", \"allowed\"), (\"lowrise\",),\n",
    "    ]\n",
    "    \n",
    "    def activate(row, kw):\n",
    "        exists = 0\n",
    "        for each in row.features_cleaned:\n",
    "            if min([each.find(w) for w in kw]) >= 0:\n",
    "                exists = 1\n",
    "                break\n",
    "        return exists        \n",
    "                    \n",
    "    for kw in keywords:\n",
    "        col = \"_\".join(kw)\n",
    "        df[col] = 0\n",
    "        df[col] = df.apply(activate, args=(kw,), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integerize_dataset(train, test, ignore_cols=None):\n",
    "    columns = (\"manager_id\", \"interest_level\", \"display_address\")\n",
    "    for col in columns:\n",
    "        if ignore_cols and col not in ignore_cols:\n",
    "            continue\n",
    "        labels, uniques = pd.factorize(train[col])\n",
    "        train[\"{0}_label\".format(col)] = labels\n",
    "        if col != \"interest_level\":\n",
    "            test[\"{0}_label\".format(col)] = uniques.get_indexer(test[col])\n",
    "        setattr(integerize_dataset, \"{0}_uniques\".format(col), uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_lat_lng(df, cnt=8, max_iter=1000):\n",
    "    lat_lng = df[[\"latitude\", \"longitude\"]].values\n",
    "    kmeans = KMeans(n_clusters=cnt, random_state=0, max_iter=max_iter).fit(lat_lng)\n",
    "    df[\"lat_lng_group\"] = kmeans.labels_\n",
    "    return kmeans\n",
    "\n",
    "group_lat_lng(train_df, 10)\n",
    "group_lat_lng(test_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started..\n",
      "cleaning features..\n",
      "cleaning description..\n"
     ]
    }
   ],
   "source": [
    "clean_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started..\n",
      "cleaning features..\n",
      "cleaning description..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suryak/anaconda/lib/python2.7/site-packages/bs4/__init__.py:219: UserWarning: \".\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "clean_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "set_tailored_features(train_df)\n",
    "set_tailored_features(test_df)\n",
    "print None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "integerize_dataset(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = [\"bathrooms\",\n",
    "\"bedrooms\",\n",
    "\"building_id\",\n",
    "\"latitude\",\n",
    "\"listing_id\",\n",
    "\"longitude\",\n",
    "\"manager_id\",\n",
    "\"price\",\n",
    "\"created_month\",\n",
    "\"created_year\",\n",
    "\"created_quarter\",\n",
    "\"days_count\",\n",
    "\"photos_count\",\n",
    "\"lat_lng_group\",\n",
    "\"dog_allowed\",\n",
    "\"cat_allowed\",\n",
    "\"fitness\",\n",
    "\"laundry\",\n",
    "\"dishwasher\",\n",
    "\"hardwood\",\n",
    "\"elevator\",\n",
    "\"doorman\",\n",
    "\"outdoor_space\",\n",
    "\"new_construction\",\n",
    "\"internet\",\n",
    "\"high_ceiling\",\n",
    "\"swimming_pool\",\n",
    "\"terrace\",\n",
    "\"balcony\",\n",
    "\"pet_allowed\",\n",
    "\"lowrise\",\n",
    "\"manager_id_label\",\n",
    "\"display_address_label\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df[c].to_csv(\"./test-cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[c].to_csv(\"./train-cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49346, 19), 19)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = [\n",
    "    \"bathrooms\", \"bedrooms\", \"created_month\", \"photos_count\", \"price\",\n",
    "    \"display_address_label\", \"manager_id_label\", \"lat_lng_group\",\n",
    "    \n",
    "    \"price_per_room\", \"price_per_lat_lng\", \"latitude\", \"longitude\", \"days_count\",\n",
    "    \n",
    "    # tailored\n",
    "#     \"dog_allowed\", \"cat_allowed\", \"fitness\", \"laundry\", \"dishwasher\", \"hardwood\", \"elevator\",\n",
    "#     \"doorman\", \"outdoor_space\", \"new_construction\", \"internet\", \"high_ceiling\", \"swimming_pool\",\n",
    "#     \"terrace\", \"balcony\", \"pet_allowed\",\n",
    "    \n",
    "    \"dog_allowed\", \"cat_allowed\", \"laundry\", \"dishwasher\", \"elevator\", \"doorman\",\n",
    "]\n",
    "X = train_df[selected_features].values\n",
    "Y = train_df[\"interest_level_label\"].values\n",
    "X.shape, len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def run_xgb(x_train, y_train, x_test, y_test=None):\n",
    "    # training params\n",
    "    xg_train = xgb.DMatrix(x_train, label=y_train)\n",
    "    params = dict(\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        sub_sample=0.6,\n",
    "        num_class=3,\n",
    "        max_depth=8\n",
    "    )\n",
    "    \n",
    "    # train the model\n",
    "    bt = xgb.train(params, xg_train)  \n",
    "    \n",
    "    # test (predict) values\n",
    "    xg_test = xgb.DMatrix(x_test, label=y_test)\n",
    "    predicted = bt.predict(xg_test)\n",
    "    \n",
    "    # check log-loss if y-test is known\n",
    "    if y_test is not None:\n",
    "        print \"Logloss: \", log_loss(y_test, predicted)\n",
    "    \n",
    "    # return predicted values\n",
    "    return predicted\n",
    "\n",
    "# bt = run_xgb(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def run_random_forest(x_train, y_train, x_test, y_test=None):\n",
    "    clf = RandomForestClassifier(n_estimators=300, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict_proba(x_test)\n",
    "    if y_test is not None:\n",
    "        print \"Logloss: \", log_loss(y_test, predicted)\n",
    "    return predicted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def run_adaboost(x_train, y_train, x_test, y_test=None):\n",
    "    clf = AdaBoostClassifier(n_estimators=60, random_state=0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict_proba(x_test)\n",
    "    if y_test is not None:\n",
    "        print \"Logloss: \", log_loss(y_test, predicted)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def run_mlp(x_train, y_train, x_test, y_test=None):\n",
    "    layers = [100, 100]\n",
    "    clf = MLPClassifier(hidden_layer_sizes=layers)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict_proba(x_test)\n",
    "    if y_test is not None:\n",
    "        print \"Logloss: \", log_loss(y_test, predicted)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_random_forest\n",
      "Logloss:  0.636797761202\n"
     ]
    }
   ],
   "source": [
    "def run_model(model_funcs):\n",
    "    for func in model_funcs:\n",
    "        print func.func_name\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            x_tr, y_tr = X[train_index, :], Y[train_index]\n",
    "            x_te, y_te = X[test_index, :], Y[test_index]\n",
    "            func(x_tr, y_tr, x_te, y_te)\n",
    "            break\n",
    "\n",
    "run_model([run_random_forest])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
